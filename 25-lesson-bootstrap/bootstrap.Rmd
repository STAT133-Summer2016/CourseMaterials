---
title: "Bootstrap"
date: "July 25, 2016"
output: html_document
---

```{r, include = FALSE}
library(ggplot2)
```


## Constructing confidence intervals

* Suppose we have 10 observations of a normally distributed random variable with unknown parameters $\mu$ and $\sigma$. 

```{r, echo = FALSE}
set.seed(12345)
x <- rnorm(10, 10, 2)
x
```

* We wish to estimate $\mu$ and give a 95% confidence interval for our estimate.
* We know that $\bar{X}$ is a normally distributed random variable with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$. 
* We can estimate $\mu$ and $\sigma$ using our sample mean and standard deviations. Call these $\bar{x}$ and $s$ respectively. Then, we can approximate the standard error of $\bar{X}$ by dividing $s$ by the sample size $n=10$.

```{r}
x_bar <- mean(x) 
x_bar
s <- sd(x)
s
se_xbar <- s/sqrt(10)
se_xbar
```

* Then, using CLT, we can approximate that 
$\bar{X}$ ~ N($\mu$ = `r x_bar`, $\sigma_{\bar{x}}^2$ = $`r se_xbar`^2$)
* To construct a 95% confidence interval for $\mu$, we need only calculate the lower and upper bounds using:

    + lowerbound = $\bar{x}$ - `qnorm(0.975)`*$\sigma_{\bar{x}}$
    + upperbound = $\bar{x}$ + `qnorm(0.975)`*$\sigma_{\bar{x}}$
    
* In this case, we find that the 95% CI is:

```{r}
d_upper <- qnorm(0.975, mean = x_bar, sd = se_xbar) - x_bar
d_upper
d_lower <- qnorm(0.025, mean = x_bar, sd = se_xbar) - x_bar
d_lower
CI <- c(x_bar - d_upper, x_bar - d_lower)
CI
```

---

# Parametric bootstrap
The bootstrap presents an alternative to building confidence intervals when
the sampling distribution of the sample average is not close to the normal 
distribution.

Suppose we have a sample of size 10 from a Poisson(0.25) distribution, but
we do not know a priori that the true value of lambda is 0.25. We wish to 
estimate lambda and give a 95% confidence interval for our estimate. 
```{r}
set.seed(123456)
pois_samp <- rpois(10, lambda = 0.25)
pois_samp
```

Calculate the sample mean, which we use as our estimator for lambda.
```{r}
x_bar <- mean(pois_samp)
x_bar
```

By the central limit theorem, we know that the distribution of x_bar
will resemble a normal distribution closely for sufficiently large n. 
But, n is only 10. Remember that how large n needs to be depends a lot on 
how skewed the underlying distribution is. In this case, looking at a histogram
of many values sampled from a Poisson(0.25) distribution tells us that the
Poisson(0.25) distribution doesn't look normal at all. 

```{r}
ggplot() +
  aes(x = rpois(1000, 0.25), y = ..density..) +
  geom_histogram()
```

In a parametric bootstrap, we use the knowledge that the values have a Poisson
distribution (as opposed to a nonparametric bootstrap, which does not use
any distributional assumptions at all). Because we do not know the lambda parameter of the Poisson distribution, a reasonable guess is to use the estimate that we obtained. 

Then, we can simulate many samples of size 10 from this distribution, calculate
the sample mean each time, and plot a histogram of the resultant sample means. 
We are mimicking the process of obtaining the sampling distribution of the mean, 
albeit with an estimated lambda rather than the true lambda.

Produce 500 samples of size 10 from a Poisson distribution with lambda =
the estimate you found in the previous chunk. Take the mean of each sample.
```{r}
set.seed(123456)
boot_samp <- replicate(500, rpois(10, lambda=x_bar))
class(boot_samp)
dim(boot_samp)
boot_xbars <- colMeans(boot_samp)
```

Plot a histogram of the sample means. Add a vertical line for the value of x_bar, the original sample mean you obtained. 
```{r}
hist(boot_xbars)
abline(v = x_bar, col = "red")
```

Intuitively, it would be incorrect to take the 97.5% and 2.5% percentiles of 
this distribution to be our confidence interval, because these values were 
simulated from a Poisson(x_bar) rather than Poisson(lambda): 
the confidence intervals produced from this method would always be off 
by |x_bar - lambda|.

However, the distribution of boot_xbars - x_bar can be seen as analogous to the distribution of x_bar - lambda. From this distribution, we can obtain our
CI widths, upper and lower. Then, our confidence interval is 
x_bar - d_upper, x_bar - d_lower. 

```{r}
d_upper = quantile(boot_xbars, probs = 0.975) - x_bar
d_lower = quantile(boot_xbars, probs = 0.025) - x_bar

c(x_bar - d_upper, x_bar - d_lower)
2*x_bar - quantile(boot_xbars, probs = c(0.975, 0.025))
```

---

## Parametric Bootstrap Procedure

1. Estimate the parameters of the distribution using the sample observations
2. Simulate a large number of samples from the distribution using your estimated parameters
3. For each bootstrap sample, compute the statistic of interest
4. Estimate the sampling distribution of your statistic of interest

---

## Nonparametric Bootstrap

Now, suppose that we were doing this same problem, but we weren't given any information on the distribution of our sample. Given only the sample data, how can we construct a 95% confidence interval for the mean?

```{r}
set.seed(123456)
samp <- rpois(10, lambda = 0.25)
samp
```

As before, we take the sample mean as an estimator for $\bar{X}$

```{r}
x_bar <- mean(samp)
x_bar
```


Recall that earlier, we simulated many samples of size 10 from the resulting distribution. We then calculated the means of the resultant samples to obtain the empirical sampling distribution of $\bar{X}$.

Because here, we have no distribution to simulate samples from, nonparametric bootstrapping uses sampling with replacement to generate multiple samples of size n. 
Produce 500 samples of size 10 from the given observations, then take the mean of each resultant sample.

```{r}
set.seed(12345)
boot_samp2 <- replicate(500, sample(samp, size = 10, replace = TRUE))
boot_xbars2 <- colMeans(boot_samp2)
```

We can then follow the same procedure as before to get the desired confidence interval:

```{r}
d_upper = quantile(boot_xbars2, probs = 0.975) - x_bar
d_lower = quantile(boot_xbars2, probs = 0.025) - x_bar

c(x_bar - d_upper, x_bar - d_lower)
2*x_bar - quantile(boot_xbars2, probs = c(0.975, 0.025))
```

---

## Nonparametric Bootstrap Procedure

1. Estimate the parameters of the distribution using the sample observations
2. Simulate a large number of samples from the distribution by sampling with replacement from the given sample
3. For each bootstrap sample, compute the statistic of interest
4. Estimate the sampling distribution of your statistic of interest

---

## When does bootstrap fail?

* sample is not representative of the population
* incomplete data (missing data)
* dependent data (e.g. correlated time series)
* too many outliers
